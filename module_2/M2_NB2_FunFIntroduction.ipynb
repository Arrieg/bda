{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">Python 2.7 Jupyter Notebook</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Funf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your completion of the notebook exercises will be graded based on your ability to: \n",
    "\n",
    "> **Apply**: Are you able to execute code, using the supplied examples, that perform the required functionality on supplied or generated data sets? \n",
    "\n",
    "> **Evaluate**: Are you able to interpret the results and justify your interpretation based on the observed data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook introduction\n",
    "\n",
    "Data from the following two publicly available datasets will be used:\n",
    "1. [Friends and Family](http://realitycommons.media.mit.edu/friendsdataset.html) by MIT Media Lab, and \n",
    "2. [Student Life](http://studentlife.cs.dartmouth.edu/dataset.html) by Dartmouth college. \n",
    "\n",
    "The \"Friends and Family\" dataset was generated using Funf. The \"Student Life\" data set contains similar data and while not created using Funf, Funf is quoted as one of its main sources of inspiration. You can read more about the data sets in the provided links.\n",
    "\n",
    "> **Note**:\n",
    ">[Funf](https://github.com/OpenSensing/funf-core-android) was introduced to you in Video 4 of this module. You are welcome to review the code on GitHub, as well as download and create your own application. Should you wish to do so, it is a good idea to start [here](https://github.com/funf-org/funf-core-android/wiki/WifiScannerTutorial).\n",
    "\n",
    "In the exercises that follow, you will familiarize yourself with some of the key features of the two datasets. The first exercise will focus on social features, namely: Call logs and SMS. In the second exercise you will visualize the mobility trace for a user over a week, as well as for the term.\n",
    "\n",
    "There are many other features that can be explored in the datasets. Many of them are labeled as “technical”, as a certain degree of wrangling is required before they can be used to analyze networks of social interactions.\n",
    "\n",
    "\n",
    "The features demonstrated and contained in the datasets do not form a comprehensive list of all the possible sensor datasets. Additional options include accelerometer data used by fitness trackers, “screen on\" status, and many others. When analyzing populations you will most likely start with the basics. You will then expand on these basics with additional features where available, as well as where you have analyzed the additional datasets and found them to be useful in solving the particular problem that you are trying to solve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: \n",
    "\n",
    "> It is strongly recommended that you save a checkpoint after applying significant changes or completing exercises. This allows you to return the notebook to a previous state should you wish to do so. On the Jupyter menu, select \"File\", then \"Save and Checkpoint\" from the dropdown menu that appears."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load libraries and set options\n",
    "As usual, our Python toolbox consists of pandas and numpy. Folium is also added, as maps will be added to this notebook at a later stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (10, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Friends and Family - Call logs and SMS\n",
    "You will run sample scripts to examine the datasets and visualize the timelines of various sensor readings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Analyze the call log of a single user\n",
    "The \"Friends and Family\" dataset contains all users' calls in one file. One participant, \"fa10-01-08\", has been chosen as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Analyze CallLog\n",
    "\n",
    "#### Data preparation\n",
    "\n",
    "To start our analysis, we will:\n",
    "- Load the dataset.\n",
    "- Parse the datetime and sort the dataset by this column.\n",
    "- Filter the dataset to review a single user.\n",
    "- Examine the top rows in our new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the dataset.\n",
    "calls = pd.read_csv('../data/CallLog.csv')\n",
    "\n",
    "# Parse datetimes using the Pandas function.\n",
    "calls['local_time'] = pd.to_datetime(calls['local_time'])\n",
    "\n",
    "# Index the dataset by the datetime column.\n",
    "calls.set_index('local_time', inplace=True)\n",
    "\n",
    "# Sort the dataset in place.\n",
    "calls.sort_index(inplace=True)\n",
    "\n",
    "# Set the user to be evaluated.\n",
    "example_user = 'fa10-01-08'\n",
    "\n",
    "# Create a subset of the data where participantID.A \n",
    "#     is the selected user using the copy method.\n",
    "call_example = calls[calls['participantID.A'] == example_user].copy()\n",
    "\n",
    "# Add a column where the week is derived from the datetime column.\n",
    "call_example['week'] = call_example.index.map(lambda observation_timestamp: \n",
    "                                              observation_timestamp.week)\n",
    "\n",
    "# Display the head of the new dataset.\n",
    "call_example.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the unique types of records present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display the unique records for \"type\"\n",
    "call_example.type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the weekly bins for the records of the types that we are interested in will be created, and the weekly summary will be displayed. Missed calls have been excluded for the purpose of this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a new variable, call_groups, containing call_example grouped by week.\n",
    "call_groups = call_example.groupby(['week'], sort=False)\n",
    "\n",
    "# Create a pandas dataframe.\n",
    "call_weeks = pd.DataFrame(columns=['week', 'outgoing', 'incoming', 'total'])  \n",
    "\n",
    "# Set the index for the new dataframe.\n",
    "call_weeks.set_index('week', inplace=True)\n",
    "\n",
    "# Next we create a summary table based on the observed types.\n",
    "for week, group in call_groups:\n",
    "    inc = 0\n",
    "    out = 0\n",
    "    \n",
    "    try:\n",
    "        inc += pd.value_counts(group.type)['incoming+']\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        inc += pd.value_counts(group.type)['incoming']\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    try:    \n",
    "        out += pd.value_counts(group.type)['outgoing+']\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    try:    \n",
    "        out += pd.value_counts(group.type)['outgoing']\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    call_weeks.loc[week] = [out, inc, out+inc]\n",
    "\n",
    "# Display the head of our new dataset.\n",
    "call_weeks.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calls per week can now be visualized using a barplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set plotting options\n",
    "fig, ax = plt.subplots()\n",
    "tight_layout()\n",
    "\n",
    "# Add outgoing calls to our plot\n",
    "plt.bar(call_weeks.reset_index()['week'], call_weeks['outgoing'], \n",
    "        color='b', label='outgoing')\n",
    "\n",
    "# Add incoming calls to our plot\n",
    "plt.bar(call_weeks.reset_index()['week'], call_weeks['incoming'], \n",
    "        color='r', bottom=call_weeks['outgoing'], label='incoming')\n",
    "\n",
    "# Plot formatting options\n",
    "ax.set_xlabel(\"Week Number\", fontsize=14)\n",
    "ax.set_ylabel(\"Number of Calls\", fontsize=14)\n",
    "ax.set_title(\"User's calls per week\", fontsize=16)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Analyze SMS\n",
    "\n",
    "The exercise in the previous section will now be repeated with the SMS records for the same user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the dataset.\n",
    "sms = pd.read_csv('../data/SMSLog.csv')\n",
    "\n",
    "# Parse datetimes using the Pandas function.\n",
    "sms['local_time'] = pd.to_datetime(sms['local_time'] )\n",
    "\n",
    "# Index the dataset by the datetime column.\n",
    "sms.set_index('local_time', inplace=True)\n",
    "\n",
    "# Sort the dataset in place.\n",
    "sms.sort_index(inplace=True)\n",
    "\n",
    "# We have set the user to be evaluated in the call logs section and will \n",
    "#     reference the variable here. Create a subset of the data where \n",
    "#     participantID.A is the selected user using the copy method.\n",
    "sms_example = sms[sms['participantID.A'] == example_user].copy()\n",
    "\n",
    "# Add a column where the week is derived from the datetime column.\n",
    "sms_example['week'] = sms_example.index.map(lambda observation_timestamp: \n",
    "                                            observation_timestamp.week)\n",
    "\n",
    "# Display the head of the new dataset.\n",
    "sms_example.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the unique types of records present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sms_example.type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the weekly bins for the records of the types that we are interested in are created again (as was done in the previous section), and the weekly summary will be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a new variable, sms_groups, containing call_example grouped by week.\n",
    "sms_groups = sms_example.groupby(['week'], sort=False)\n",
    "\n",
    "# Create a pandas dataframe.\n",
    "sms_weeks = pd.DataFrame(columns=['week', 'outgoing', 'incoming', 'total'])  \n",
    "\n",
    "# Set the index for the new dataframe.\n",
    "sms_weeks.set_index('week', inplace=True)\n",
    "\n",
    "# Next we create a summary table based on the observed types.\n",
    "for week, group in sms_groups:\n",
    "    try:\n",
    "        inc = pd.value_counts(group.type)['incoming']\n",
    "    except KeyError:\n",
    "        inc = 0\n",
    "        \n",
    "    try:    \n",
    "        out = pd.value_counts(group.type)['outgoing']\n",
    "    except KeyError:\n",
    "        out = 0\n",
    "    sms_weeks.loc[week] = [out, inc, out+inc]\n",
    "\n",
    "# Display the head of our new dataset.\n",
    "sms_weeks.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SMSs per week can now be visualized using a barplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set plotting options\n",
    "fig, ax = plt.subplots()\n",
    "tight_layout()\n",
    "\n",
    "# Add outgoing sms to our plot\n",
    "plt.bar(sms_weeks.reset_index()['week'], sms_weeks['outgoing'], \n",
    "        color='b', label='outgoing')\n",
    "\n",
    "# Add incoming sms to our plot\n",
    "plt.bar(sms_weeks.reset_index()['week'], sms_weeks['incoming'], \n",
    "        color='r', bottom=sms_weeks['outgoing'], label='incoming')\n",
    "\n",
    "# Plot formatting options\n",
    "ax.set_xlabel(\"Week Number\", fontsize=14)\n",
    "ax.set_ylabel(\"Number of SMS\", fontsize=14)\n",
    "ax.set_title(\"User's SMS per week\", fontsize=16)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> **Note**:\n",
    "\n",
    "> You can select other users and re-execute the cells above for both call and sms logs to test your intuition about the differences in behaviour of students should you wish to do so. This activity will not be graded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dartmouth - Location history example\n",
    "You will run sample scripts to examine the dataset and visualize the timeline of the location data. The Dartmouth dataset has been selected for this example because the locations in the \"Friends and Family\" dataset are encrypted and not suitable for use in this visual exercise.\n",
    "\n",
    "### 2.1 Analyze the location of a single user\n",
    "The \"Student Life\" dataset contains separate files for each of the users. User 31 has been selected for this example.\n",
    "\n",
    "Data preparation will need to be completed before our analysis can start. The following tasks will need to be carried out: load the dataset, parse the datetime, and sort it by this column. The dataset will then need to be filtered to review a single user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the dataset and display the head.\n",
    "loc = pd.read_csv('../data/dartmouth/location/gps_u31.csv')\n",
    "loc.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output above, the GPS coordinates are visible, and the dataset is very similar in structure to the \"Friends and Family\" dataset. In order to be able to work with this data as a chronological location trace, it needs to be indexed with sorted timestamps (in human-readable ISO format). The next step is to review the summary statistics of the re-indexed dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parse the dates.\n",
    "loc['time'] = pd.to_datetime(loc['time'], unit='s')\n",
    "\n",
    "# Set and reindex.\n",
    "loc.set_index('time', inplace=True)\n",
    "loc.sort_index(inplace=True)\n",
    "\n",
    "# Display the head.\n",
    "loc.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieve the start and end dates for the dataset and print the output.\n",
    "start = pd.to_datetime(loc.index, unit='s').min()\n",
    "end   = pd.to_datetime(loc.index, unit='s').max()\n",
    "print (\"Data covers {} between {} and {}\".format(end - start, start, end))\n",
    "\n",
    "# Calculate the median interval between observations and print the output.\n",
    "median_interval = pd.Series(pd.to_datetime(loc.index, \n",
    "                                               unit='s')).diff().median().seconds / 60\n",
    "print (\"It has {} datapoints sampled with median interval of {} minutes.\"\n",
    "       .format(len(loc), median_interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the step to add a column with the week will be repeated, and the dataframe will be grouped by this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add a column containing the week.\n",
    "loc['week'] = loc.index.map(lambda observation_timestamp: \n",
    "                            observation_timestamp.week)\n",
    "loc.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the number of observations per week by grouping the data by the column added in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Group by week and review the output.\n",
    "week_gr = loc.groupby('week', axis=0)\n",
    "pd.DataFrame(week_gr.size(), columns=['# of observations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the data will be plotted on a map. Some additional steps to prepare the data are required before this can be done. \n",
    "\n",
    "The coordinates from the location dataframe need to be extracted into a simpler format, one without indexes, column names, and unnecessary columns. This example will work on the weekly groupings and use dataframe df.as_matrix() methods, which return a raw numpy matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weekly_travels = {}\n",
    "\n",
    "for week, points in week_gr:\n",
    "    weekly_travels[week] = points[['latitude', 'longitude']].as_matrix() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: \n",
    "\n",
    "> The Python visualization library, Folium, was introduced in an earlier notebook, but it is good to know that the center location and starting zoom level are options that you will need to set. In many cases your analysis will be centered around a known coordinate, in which case you can manually update the location. In other cases you will need to calculate the position based on your available data.\n",
    "\n",
    "Now you can plot the data. The following example looks at a specific week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set the center of the map and the zoom level. \n",
    "map_week15 = folium.Map(location=[43.706607,-72.287041], zoom_start=11)\n",
    "# Plot the locations of observations.\n",
    "folium.PolyLine(weekly_travels[15], color='blue', weight=3, \n",
    "                opacity=0.5).add_to(map_week15)\n",
    "map_week15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise 1 Start.</b>\n",
    "</div>\n",
    "\n",
    "### Instructions\n",
    "> Copy the code in the previous cell and change week 15 to week 20 to produce the mobility trace for week 20. You need to replace \"map_week15\" with \"map_week20\" and retrieve element 20 from \"weekly_travels[]\".\n",
    "\n",
    "> Additional option: Should you wish to do so, you can attempt to recenter the map and specify a different zoom level to produce a map that is better suited to the visualization. (The answer is demonstrated in the mobility trace for all data for the user further down in this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise 1 End.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise complete**:\n",
    "    \n",
    "> This is a good time to \"Save and Checkpoint\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise 2 Start.</b>\n",
    "</div>\n",
    "\n",
    "### Instructions\n",
    "> When comparing the visual representation of the two weeks, you will see that the patterns are very similar. Please provide your high-level summary of the person's mobility in the cell below.\n",
    "\n",
    "> Here are some questions to guide your answer:\n",
    "- How many places do you think the person visited during week 15?\n",
    "- Look at a couple of other weeks and indicate whether you think this person's behavior is predictable.\n",
    "- Do you think this is a representative of general behavior, or do you think the number of places visited is lower or higher than you expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your markdown answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise 2 End.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise complete**:\n",
    "    \n",
    "> This is a good time to \"Save and Checkpoint\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's look at the mobility trace for all of the data for this user.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Retrieve all locations\n",
    "all_points = loc[['latitude', 'longitude']].as_matrix()\n",
    "\n",
    "map_alltime = folium.Map(location=[42.9297,-71.4352], zoom_start=8)\n",
    "folium.PolyLine(all_points ,color='blue', weight=2, \n",
    "                opacity=0.5).add_to(map_week15).add_to(map_alltime)\n",
    "map_alltime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise 3 Start.</b>\n",
    "</div>\n",
    "\n",
    "### Instructions\n",
    "\n",
    "> What conclusions can you derive when comparing the person's mobility from the single weeks to the full dataset? Please provide your high-level summary in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your markdown answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise 3 End.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise complete**:\n",
    "    \n",
    "> This is a good time to \"Save and Checkpoint\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. SocialfMRI: Investigating and shaping social mechanisms in the real world, Nadav Aharony, Wei Pan, Cory Ip,Inas Khayal, Alex Pentland, Pervasive and Mobile Computing, Volume 7, Issue 6, December 2011, Pages 643-659\n",
    "\n",
    "2. Wang at al. *StudentLife: Assessing Mental Health, Academic Performance and Behavioral Trends of College Students \n",
    "    using Smartphones* In Proceedings of the ACM Conference on Ubiquitous Computing. 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Submit your notebook\n",
    "\n",
    "Please make sure that you:\n",
    "- Perform a final \"Save and Checkpoint\";\n",
    "- Download a copy of the notebook in \".ipynb\" format to your local machine using \"File\", \"Download as\", and \"IPython Notebook (.ipynb)\"; and\n",
    "- Submit a copy of this file to the online campus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
