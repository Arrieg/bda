{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">Python 2.7 Jupyter Notebook</div>\n",
    "\n",
    "# Network Analysis Exercises Using 'Friends and Family' Dataset \n",
    "\n",
    "<br><div class=\"alert alert-warning\">\n",
    "<b>Note that this notebook contains advanced exercises applicable only to students who wish to deepen their understanding and qualify for bonus marks as part of the technical track.</b> You will be able to achieve 100% for this notebook by only completing exercise 1. Optional advanced exercises can be completed to qualify for bonus marks.\n",
    "</div>\n",
    "\n",
    "## Part 2: Clustering\n",
    "\n",
    "### Your completion of the notebook exercises will be graded based on your ability to:\n",
    "\n",
    "> **Understand**: Does your pseudo-code and/or comments show evidence that you recall and understand technical concepts?\n",
    "\n",
    "> **Apply**: Are you able to execute code, using the supplied examples, that perform the required functionality on supplied or generated data sets? \n",
    "\n",
    "> **Analyze**: Are you able to pick the relevant method, library or resolve specific stated questions?\n",
    "\n",
    "> **Evaluate**: Are you able to interpret the results and justify your interpretation based on the observed data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Community detection is an important task in social network analysis. The idea behind it is to identify groups of people that share a common interest, based on the assumption that these people tend to link to each other more often than to the rest of the network. Specifically, real-world networks exhibit clustering behavior that can be observed in the graph representation (of these networks) by the formation of clusters or partitions. These groups of nodes on a graph (clusters) correspond to communities that share common properties, or have a common role in the system under study.\n",
    "\n",
    "Intuitively, it is expected that such clusters are associated with a high concentration of nodes. In the following examples, you will explore the identification of these clusters using the following approaches as discussed in the video lectures:\n",
    "\n",
    "1. Hierarchical clustering (using a distance matrix);\n",
    "2. The Louvain Algorithm (using modularity maximization); and\n",
    "3. Spectral graph partitioning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import operator\n",
    "\n",
    "## For hierarchical clustering.\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial import distance\n",
    "\n",
    "## For spectral graph partitioning.\n",
    "from sklearn.cluster import spectral_clustering as spc\n",
    "\n",
    "## For Community Detection (Louvain Method).\n",
    "import community\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils import draw_partitioned_graph\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 9)\n",
    "plt.rcParams['axes.titlesize'] = 'large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are going to read the graph from an adjacency list saved in the earlier exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "call_adjmatrix = pd.read_csv('./call.adjmatrix', index_col=0)\n",
    "call_graph     = nx.from_numpy_matrix(call_adjmatrix.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display call graph object.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.axis('off')\n",
    "\n",
    "pos = nx.spring_layout(call_graph)\n",
    "\n",
    "nx.draw_networkx_nodes(call_graph, pos=pos, node_color='#11DD11')\n",
    "nx.draw_networkx_edges(call_graph, pos=pos, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will make use of a hierarchical clustering algorithm as implemented in [Scipy](http://docs.scipy.org/doc/scipy/reference/). The following example uses the average distance measure. Since the graph is weighted, you can also use the single linkage inter-cluster distance measure (see exercises)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_hc(G, t=3, linkage='max'):\n",
    "    \"\"\"\n",
    "    Creates hierarchical cluster of graph G from distance matrix\n",
    "    \n",
    "    'Erika Fille Legara <legareft@ihpc.a-star.edu.sg>',\n",
    "    'Maksim Tsvetovat <maksim@tsvetovat.org',\n",
    "    'Drew Conway <drew.conway@nyu.edu>',\n",
    "    'Aric Hagberg <hagberg@lanl.gov>'\n",
    "    'Gorden Jemwa <>' : modifications: set t argument with default, \n",
    "                                       accept linkage with default as an argument\n",
    "    \"\"\"\n",
    "    path_length=nx.all_pairs_shortest_path_length(G)\n",
    "    distances=np.zeros((len(G),len(G)))\n",
    "    labels=G.nodes() # keep node labels.\n",
    "    for u,p in path_length.items():\n",
    "        for v,d in p.items():\n",
    "            #distances[u][v]=d\n",
    "            distances[G.nodes().index(u)][G.nodes().index(v)] = d\n",
    "            distances[G.nodes().index(v)][G.nodes().index(u)] = d\n",
    "            if u==v: distances[G.nodes().index(u)][G.nodes().index(u)]=0\n",
    "    # Create hierarchical cluster.\n",
    "    Y=distance.squareform(distances)\n",
    "    if linkage == 'max':\n",
    "        # Creates HC using farthest point linkage.\n",
    "        Z=hierarchy.average(Y)  \n",
    "    if linkage == 'single':\n",
    "        # Creates HC using closest point linkage.\n",
    "        Z=hierarchy.single(Y)  \n",
    "\n",
    "    # This partition selection is arbitrary, for illustrative purposes.\n",
    "    membership=list(hierarchy.fcluster(Z,t=t, criterion='inconsistent'))\n",
    "    \n",
    "    # Create collection of lists for blockmodel.\n",
    "    partition = defaultdict(list)\n",
    "    for n,p in zip(list(range(len(G))),membership):\n",
    "        partition[p].append(labels[n])\n",
    "    \n",
    "    return Z, membership, partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a demonstration of hierarchical clustering when applied to the call graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform hierarchical clustering using 'max' linkage. \n",
    "# Return the distance matrix, node membership list and collection lists for block model.\n",
    "Z, membership, blk_clusters = create_hc(call_graph, t=1.15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map membership values to a dictionary variable.\n",
    "hc_partition = {}\n",
    "i = 0\n",
    "for i in range(len(membership)):\n",
    "    hc_partition[i]=membership[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize the clustering.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.axis('off')\n",
    "\n",
    "pos = nx.spring_layout(call_graph)\n",
    "\n",
    "nx.draw_networkx_nodes(call_graph, pos=pos, node_color=hc_partition.values())\n",
    "nx.draw_networkx_edges(call_graph, pos=pos, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two remarks are in order with regard to the clustering result obtained. \n",
    "\n",
    "The first is that cluster assignment is determined inside our **create_hc** function, specifically the call \n",
    "\n",
    "`hierarchy.fcluster(Z,t=t, criterion='inconsistent')`\n",
    "\n",
    "where t is a threshold (scalar value, t=1.15 in our case) and criterion is the criterion used in forming flat clusters (of which there are five options, with *inconsistent* the default). We have specified reasonable values for these estimates but typically the user needs to optimize these base on a good understanding of the problem domain and the clustering technique. \n",
    "\n",
    "Secondly, the visualization of our clusters is not perfect because of the constraints imposed by the node positioning layout algorithm. Unfortunately, NetworkX does not  provide ideal visualization tools to improve the graph display. However, the correct interpretation is that nodes with close or similar color belong to the same cluster (despite the poor reflection of this in the visualization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dendrogram corresponding to the above illustrated partitioned graph is obtained as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierarchy.dendrogram(Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dendrogram can help explain what happens as a result of the agglomerative method of hierarchical clustering. Starting at the bottom-most level, each node is assigned its own cluster. The closest pair of nodes (according to a distance function) are then merged into a new cluster. The distance matrix is recomputed, treating the merged cluster as an individual node. This process is repeated until the entire network has been merged into a single large cluster, which the top level in the dendrogram above represents. You can now understand why this method is agglomerative.\n",
    "\n",
    "The linkage function is used to determine the distance between a cluster and a node, or between two clusters, using the following possibilities:\n",
    "\n",
    "1. Single: merge two clusters with the smallest minimum pairwise distance.\n",
    "2. Average: merge two clusters with the smallest average pairwise distance.\n",
    "3. Maximum or complete: merge the two clusters with the smallest maximum pairwise distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise 1 Start.</b>\n",
    "</div>\n",
    "\n",
    "### Instructions\n",
    "\n",
    "> 1. How many clusters are obtained after the final step of agglomerative clustering before post-processing? \n",
    "> 2. Based on your answer above, would you consider agglomerative clustering a 'top down' approach or a 'bottom up' approach?.\n",
    "> 3. Which of the three linkage functions listed above (i.e. single, average, maximum/complete) above do you think is likely to be most sensitive to outliers? **Hint**: See this [link](http://nlp.stanford.edu/IR-book/html/htmledition/single-link-and-complete-link-clustering-1.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your markdown answer here.\n",
    "\n",
    "1. \n",
    "2. \n",
    "3. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise 1 End.</b>\n",
    "</div>\n",
    "> **Exercise complete**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Block models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph network can be simplified using block models, in which all nodes in a cluster are merged into a single node. Relationships between original nodes become aggregated into relationships between blocks or communities.\n",
    "\n",
    "You can use results from your hierarchical clustering to create the block model. NetworkX has a function to build a block model which accepts the graph model and cluster information from the hierarchical clustering, as illustrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M=nx.blockmodel(call_graph,blk_clusters.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.axis('off')\n",
    "\n",
    "pos = nx.spring_layout(M)\n",
    "\n",
    "nx.draw_networkx_nodes(M, pos=pos, node_color='#11DD11')\n",
    "nx.draw_networkx_edges(M, pos=pos, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise 2 [Advanced exercise for bonus marks] Start.</b>\n",
    "</div>\n",
    "\n",
    "### Instructions\n",
    "\n",
    "> Load the SMS graph adjacency matrix from what you created in previous exercises into a variable called SMS_graph.\n",
    "\n",
    "> 1. Run hierarchical clustering using a default argument setting on SMS_graph, and assign the outputs to: Z_1, membership_1, and blk_clusters_1.\n",
    "> 2. Initialize an empty dict variable: partition_1.\n",
    "> 3. Assign corresponding items in the list membership_1 to the dict partition_1.\n",
    "> 4. Draw the SMS_graph with cluster information superimposed to reveal communities in the graph.\n",
    "> 5. Plot the corresponding dendrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise 2 End.</b>\n",
    "</div>\n",
    "> **Exercise complete**:\n",
    "    \n",
    "> This is a good time to \"Save and Checkpoint\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise 3 [Advanced exercise for bonus marks] Start.</b>\n",
    "</div>\n",
    "\n",
    "### Instructions\n",
    "\n",
    "> 1. Repeat Exercise 2, using single link distance measure.\n",
    "> 2. How do the uses of single and average distance measures compare? A qualitative description is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise 3 End.</b>\n",
    "</div>\n",
    "> **Exercise complete**:\n",
    "    \n",
    "> This is a good time to \"Save and Checkpoint\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Community detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The Louvain Modularity Maximization Approach.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Louvain method is one of the most widely-used methods for detecting communities in large networks. It was developed by a team of researchers at the the Université catholique de Louvain. It can unveil hierarchies of communities, and allows you to zoom within communities to discover sub-communities, sub-sub-communities, and so forth. The modularity QQ quantifies how good a \"community\" or partition is, and is defined as:\n",
    "\n",
    "$$Q_c =\\frac{1}{2m}\\sum _{(ij)} \\left [ A_{ij}-\\frac{k_ik_j}{2m} \\right] \\delta(c_i, c_j)$$\n",
    "\n",
    "The higher the $Q_c$ of a community is, the better the partition is.\n",
    "\n",
    "The Louvain method is a greedy optimization method that attempts to optimize the \"modularity\" of a partition of the network via two steps:\n",
    "\n",
    "1. Locally optimize the modularity to identify \"small\" communities.\n",
    "2. Aggregate nodes belonging to the same community, and create a new network with aggregated nodes as individual nodes.\n",
    "\n",
    "Steps 1 and 2 are then repeated until a maximum of modularity results in a hierarchy of communities being produced.\n",
    "\n",
    "Now you have the opportunity to identify communities in the “Family & Friends” call data set. First, compute the best partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "louvain_partition = community.best_partition(call_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can identify and label the communities similarly to what you did when using agglomerative hierarchical clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(call_graph)\n",
    "nx.draw_networkx_nodes(call_graph, pos, cmap=plt.cm.RdYlBu, node_color=louvain_partition.values())\n",
    "nx.draw_networkx_edges(call_graph, pos, alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As remarked above, the visualization of our clusters is not perfect because of the constraints imposed by the node positioning layout algorithm. The correct interpretation is that nodes with close or similar color belong to the same cluster (despite the poor reflection of this in the visualization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Spectral graph partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral graph partitioning and clustering is based on the spectrum — the eigenvalues and associated eigenvectors — of the Laplacian matrix corresponding to a given graph. The approach is mathematically complex but involves performing a $k$-means clustering on a spectral projection of the graph with $k$=2, using an adjacency matrix as the affinity. A schematic illustration of the process is depicted in the figure below.\n",
    "\n",
    "**Optional**: You can read more about spectral graph processing [here](https://devblogs.nvidia.com/parallelforall/fast-spectral-graph-partitioning-gpus/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img\\spectral_graph_part.png\", width=750, height=550>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply spectral graph partitioning to your call graph and visualize the resulting community structure. You can read more about [Scikit-Learn](http://scikit-learn.org/stable/index.html) and the [Spectral Clustering](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html) function utilized in this section. Spectral graph partitioning needs input of the number of clusters sought (default setting is 8), and there are various approaches one can take to optimize the final number of clusters depending on problem domain knowledge. Below we use $k=5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the spectral partition using the spectral clustering function from Scikit-Learn.\n",
    "spectral_partition = spc(call_adjmatrix.as_matrix(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(call_graph)\n",
    "nx.draw_networkx_nodes(call_graph, pos, cmap=plt.cm.RdYlBu, node_color=spectral_partition)\n",
    "nx.draw_networkx_edges(call_graph, pos, alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is interesting in this view is the cluster of size 1 (yellow color)! It does appear to be an outlier and not reflective of the general call patterns that are shown by other nodes in the network. We may want to understand this node better through further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise 4 [Advanced exercise for bonus marks] Start.</b>\n",
    "</div>\n",
    "\n",
    "### Instructions\n",
    "> 1. Using SMS_graph (H) that you saved from a previous exercise, rerun the above steps and show (visually) the results of running the following approaches:<br>\n",
    ">   a. Louvain method; and<br>\n",
    ">   b. Spectral graph partitioning.\n",
    "\n",
    "> **Note**:\n",
    "\n",
    "> Interpretation of the results requires knowledge of the clustering techniques not explored in detail here.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise 4 End.</b>\n",
    "</div>\n",
    "> **Exercise complete**:\n",
    "    \n",
    "> This is a good time to \"Save and Checkpoint\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Submit your notebook\n",
    "\n",
    "Please make sure that you:\n",
    "- Perform a final \"Save and Checkpoint\";\n",
    "- Download a copy of the notebook in \".ipynb\" format to your local machine using \"File\", \"Download as\", and \"IPython Notebook (.ipynb)\"; and\n",
    "- Submit a copy of this file to the online campus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
